{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "batch_size = 128\n",
    "\n",
    "x = tf.placeholder('float', [None, 784])\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "keep_rate = 0.8\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def maxpool2d(x):\n",
    "    #                        size of window         movement of window\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolutional_neural_network(x):\n",
    "    weights = {'W_conv1':tf.Variable(tf.random_normal([5,5,1,64])),\n",
    "               'W_conv2':tf.Variable(tf.random_normal([5,5,64,128])),\n",
    "               'W_fc':tf.Variable(tf.random_normal([7*7*128,2048])),\n",
    "               'out':tf.Variable(tf.random_normal([2048, n_classes]))}\n",
    "\n",
    "    biases = {'b_conv1':tf.Variable(tf.random_normal([64])),\n",
    "               'b_conv2':tf.Variable(tf.random_normal([128])),\n",
    "               'b_fc':tf.Variable(tf.random_normal([2048])),\n",
    "               'out':tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    conv1 = tf.nn.relu(conv2d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "    conv1 = maxpool2d(conv1)\n",
    "    \n",
    "    conv2 = tf.nn.relu(conv2d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "    conv2 = maxpool2d(conv2)\n",
    "\n",
    "    fc = tf.reshape(conv2,[-1, 7*7*128])\n",
    "    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
    "\n",
    "    output = tf.matmul(fc, weights['out'])+biases['out']\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(x):\n",
    "    prediction = convolutional_neural_network(x)\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels = y) )\n",
    "    optimizer = tf.train.RMSPropOptimizer(0.005).minimize(cost)\n",
    "    \n",
    "    hm_epochs = 20\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "\n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            m = [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]\n",
    "            p = []\n",
    "            for _ in range(1):\n",
    "                for i in range(10, 110):\n",
    "                    epoch_x = Image.open('/home/mahesh/rishiTensorflow/updated-images/' + str(i) + 'cropblack.png');\n",
    "                    epoch_x = np.asarray(epoch_x) / 255\n",
    "                    k = []\n",
    "                    for i1 in range(28):\n",
    "                        for i2 in range(28):\n",
    "                            k.append(epoch_x[i1][i2][0])\n",
    "                    p.append(k)\n",
    "                epoch_x = np.array(p)\n",
    "                \n",
    "                epoch_y = m\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "                epoch_loss += c\n",
    "\n",
    "            print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "\n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        p = []\n",
    "        for i in range(10, 110):\n",
    "            epoch_x = Image.open('/home/mahesh/rishiTensorflow/updated-images/' + str(i) + 'cropblack.png');\n",
    "            epoch_x = np.asarray(epoch_x) / 255\n",
    "            k = []\n",
    "            for i1 in range(28):\n",
    "                for i2 in range(28):\n",
    "                    k.append(epoch_x[i1][i2][0])\n",
    "            p.append(k)\n",
    "        epoch_x = np.array(p)\n",
    "        epoch_y = np.array(m)\n",
    "        epoch_x, epoch_y = unison_shuffled_copies(epoch_x, epoch_y)\n",
    "        np.set_printoptions(precision=2)\n",
    "        print(prediction.eval({x:epoch_x, y:m}))\n",
    "        print('Accuracy:',accuracy.eval({x:epoch_x, y:epoch_y}))\n",
    "        print(epoch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mahesh/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch 0 completed out of 20 loss: 229898.921875\n",
      "Epoch 1 completed out of 20 loss: 734001.875\n",
      "Epoch 2 completed out of 20 loss: 688893.25\n",
      "Epoch 3 completed out of 20 loss: 644427.0\n",
      "Epoch 4 completed out of 20 loss: 493731.65625\n",
      "Epoch 5 completed out of 20 loss: 282895.6875\n",
      "Epoch 6 completed out of 20 loss: 208684.015625\n",
      "Epoch 7 completed out of 20 loss: 149738.5\n",
      "Epoch 8 completed out of 20 loss: 101574.625\n",
      "Epoch 9 completed out of 20 loss: 72036.6328125\n",
      "Epoch 10 completed out of 20 loss: 59756.84375\n",
      "Epoch 11 completed out of 20 loss: 30607.3554688\n",
      "Epoch 12 completed out of 20 loss: 24937.4140625\n",
      "Epoch 13 completed out of 20 loss: 20566.53125\n",
      "Epoch 14 completed out of 20 loss: 12208.8828125\n",
      "Epoch 15 completed out of 20 loss: 8279.87890625\n",
      "Epoch 16 completed out of 20 loss: 4021.62915039\n",
      "Epoch 17 completed out of 20 loss: 1961.92895508\n",
      "Epoch 18 completed out of 20 loss: 1671.89746094\n",
      "Epoch 19 completed out of 20 loss: 1768.67553711\n",
      "[[  5.50e+04   5.25e+04   8.07e+03   1.80e+04   2.96e+04  -1.88e+04\n",
      "    3.22e+04   4.49e+04   3.75e+03   3.32e+04]\n",
      " [  2.36e+04   7.01e+04   1.90e+03  -2.83e+04   3.60e+04   1.49e+04\n",
      "   -3.63e+03   3.69e+04   5.34e+04   5.73e+03]\n",
      " [  5.67e+04   3.71e+04   8.31e+04  -1.59e+03   1.66e+04  -1.56e+04\n",
      "   -3.25e+04  -2.12e+04   5.48e+04  -6.34e+03]\n",
      " [  1.91e+04   2.44e+04   1.15e+04  -1.93e+04   2.21e+04   5.45e+03\n",
      "    2.26e+04   2.96e+04   3.74e+04   6.03e+04]\n",
      " [  3.44e+04   9.51e+03   4.85e+04  -3.28e+04   3.69e+04  -5.83e+02\n",
      "   -4.40e+03   1.56e+04   4.00e+04   4.15e+04]\n",
      " [  7.19e+03   4.03e+04  -7.38e+03  -1.12e+03   8.43e+04   2.92e+04\n",
      "    1.76e+04   1.20e+04   2.14e+04  -1.27e+04]\n",
      " [  1.81e+04   4.04e+03  -1.96e+04   2.58e+04   3.76e+04   1.29e+04\n",
      "    3.89e+04   3.57e+04  -9.58e+03   8.28e+04]\n",
      " [  7.96e+04   1.73e+04   1.63e+04   4.83e+04   3.50e+04  -1.36e+04\n",
      "    3.15e+04   2.64e+04   2.31e+04  -1.01e+04]\n",
      " [  1.38e+04   4.73e+04   3.47e+03   8.53e+03   3.21e+04   2.95e+04\n",
      "   -6.62e+02   3.19e+04   1.16e+04   7.47e+04]\n",
      " [  1.05e+04   1.12e+03   2.38e+04   9.17e+03   1.46e+04   2.65e+04\n",
      "    6.13e+04   5.40e+03   2.20e+04   1.09e+04]\n",
      " [  3.86e+04   2.11e+04  -6.52e+03  -2.17e+04   2.89e+04   1.52e+04\n",
      "   -3.01e+03   5.63e+04   3.73e+04   3.64e+04]\n",
      " [  3.44e+04   3.49e+03   1.46e+04   6.19e+04   1.54e+04   2.90e+04\n",
      "    2.70e+04   2.55e+04   4.68e+04   4.08e+04]\n",
      " [  2.23e+03  -1.82e+04   5.80e+04  -5.08e+03   1.09e+04   9.09e+03\n",
      "    2.95e+04   2.67e+04   4.61e+04   3.56e+04]\n",
      " [  2.84e+04   2.24e+04  -6.10e+03  -4.49e+04   1.13e+04  -1.81e+04\n",
      "    1.56e+04   1.81e+04   6.56e+04   3.17e+04]\n",
      " [  3.47e+04  -4.15e+03   2.43e+04   1.75e+04   1.51e+04  -1.32e+04\n",
      "    1.89e+04   6.90e+04  -1.30e+03   9.45e+03]\n",
      " [  9.59e+03   5.04e+04   1.08e+04  -5.01e+04   1.41e+04   5.70e+04\n",
      "    9.23e+03   2.43e+04   3.48e+04   4.26e+04]\n",
      " [  3.56e+04   1.07e+04   3.59e+04   2.75e+04   4.86e+04   3.12e+04\n",
      "    3.83e+04   1.48e+04   4.19e+03   3.44e+04]\n",
      " [ -9.06e+03   5.90e+04  -9.68e+03  -1.17e+04   1.86e+04   1.48e+04\n",
      "    3.44e+04   1.49e+04   7.91e+03   2.00e+04]\n",
      " [  2.04e+04  -9.17e+03   1.45e+04   2.59e+04   1.06e+04   1.72e+04\n",
      "    4.87e+04   1.43e+04   9.22e+04   1.16e+03]\n",
      " [  1.91e+04   2.55e+04   2.42e+04  -2.91e+04   3.66e+04   5.76e+04\n",
      "    2.92e+04   1.36e+04   2.16e+04   3.07e+04]\n",
      " [  2.72e+04   3.51e+04   2.26e+04   2.88e+04   5.71e+04   1.01e+04\n",
      "    3.46e+04   1.56e+04   2.91e+04   2.78e+04]\n",
      " [ -2.22e+01  -1.17e+03   1.44e+04   1.40e+04   4.40e+04   5.29e+04\n",
      "    2.19e+04   4.10e+04   3.09e+04   2.86e+04]\n",
      " [  1.88e+04   3.82e+04   2.57e+04  -7.49e+04   8.12e+04   1.24e+04\n",
      "   -2.07e+04   5.12e+04   5.40e+04   6.11e+04]\n",
      " [  2.07e+04   4.69e+04   1.38e+04   2.32e+04   2.88e+04   2.29e+04\n",
      "    2.20e+04   1.56e+04   1.18e+04   4.04e+03]\n",
      " [  1.21e+04   6.17e+02   1.12e+04   2.47e+03   1.28e+04  -8.18e+03\n",
      "    4.74e+04   4.17e+03   4.16e+04   2.95e+04]\n",
      " [  1.21e+04   3.44e+04   8.40e+01  -2.23e+04   2.54e+04   1.31e+04\n",
      "    2.37e+04   2.82e+04   5.77e+04   4.21e+04]\n",
      " [  2.17e+04   2.59e+04   1.02e+04   9.54e+03   2.45e+04  -9.16e+03\n",
      "    3.06e+04   1.10e+04   1.83e+04   2.00e+04]\n",
      " [  4.95e+04   6.21e+04   4.88e+04  -1.34e+03   2.47e+03   2.23e+04\n",
      "   -2.32e+04   1.81e+04   3.20e+04   8.76e+04]\n",
      " [ -9.42e+03   6.86e+04  -2.45e+04   2.47e+04   4.05e+04   1.58e+04\n",
      "    4.46e+04   2.68e+04   2.73e+04   2.14e+04]\n",
      " [ -2.32e+04   6.56e+03  -4.51e+03  -1.76e+04   5.10e+04   5.57e+04\n",
      "    4.60e+04   2.24e+04   3.86e+04   3.98e+04]\n",
      " [  1.54e+04   2.41e+04   4.92e+03   4.37e+04   3.77e+04   2.38e+04\n",
      "    2.50e+04   3.03e+04   3.67e+04   9.72e+03]\n",
      " [  1.12e+05   1.22e+04   8.62e+03  -3.84e+04   1.86e+03  -1.97e+04\n",
      "   -2.72e+04   2.47e+04   1.58e+04   4.41e+04]\n",
      " [  3.63e+04   1.11e+04  -7.10e+03  -2.70e+04   2.63e+04   1.61e+04\n",
      "    2.63e+04   2.22e+03   3.07e+04   6.88e+04]\n",
      " [  5.06e+04  -1.42e+04  -2.58e+04  -5.75e+03   3.51e+04  -2.77e+03\n",
      "    6.82e+04   3.02e+04   4.94e+04   2.51e+04]\n",
      " [  5.19e+04   1.88e+04  -1.56e+04  -5.26e+04   2.94e+04   3.02e+04\n",
      "    1.38e+04   8.21e+03   3.83e+04   3.14e+04]\n",
      " [  2.48e+04  -4.70e+03   1.23e+03   9.62e+03   2.22e+04   7.78e+03\n",
      "    5.05e+03   1.71e+04   7.88e+04   1.36e+04]\n",
      " [  2.30e+04   1.95e+04   3.56e+03   6.87e+04   2.75e+04   2.17e+03\n",
      "    3.50e+04   3.10e+04   3.76e+04   3.30e+04]\n",
      " [  1.62e+04   5.54e+04   1.70e+04   4.26e+04   1.17e+04  -6.29e+01\n",
      "    2.09e+04   2.72e+04   9.98e+03   2.56e+04]\n",
      " [  5.72e+04   4.40e+04   2.84e+04   1.09e+04   2.48e+04  -1.34e+04\n",
      "    2.39e+04   2.99e+04   1.01e+05   4.20e+04]\n",
      " [  7.23e+04   2.21e+04   9.96e+03   5.69e+03   5.15e+03  -3.41e+03\n",
      "    1.05e+04  -4.40e+03   2.50e+04   3.55e+04]\n",
      " [  8.21e+03   4.52e+04  -6.85e+03  -3.21e+03   4.51e+04  -4.85e+03\n",
      "    3.41e+04   3.58e+04   2.77e+03   7.53e+04]\n",
      " [ -2.20e+03   6.49e+04   1.51e+04  -3.92e+04   1.94e+04   4.38e+04\n",
      "    3.88e+04   1.17e+04   1.83e+04   4.20e+04]\n",
      " [  1.13e+04   2.20e+04   5.73e+03   2.34e+04   1.38e+04   9.66e+03\n",
      "    1.52e+04   2.38e+04   2.48e+04   5.17e+04]\n",
      " [  2.32e+04   3.30e+04   1.48e+04  -4.84e+04   2.83e+04   3.63e+04\n",
      "    1.14e+04   4.45e+04   2.64e+04   7.60e+04]\n",
      " [  3.61e+04   1.23e+04   1.25e+04   4.64e+04   1.86e+04  -1.17e+04\n",
      "    1.57e+04   3.26e+04   1.98e+03   4.22e+04]\n",
      " [ -2.30e+04   1.30e+04  -3.70e+04  -5.15e+04   1.55e+05  -2.72e+04\n",
      "    3.84e+04   8.21e+04   3.36e+04   7.92e+04]\n",
      " [  2.35e+04   2.33e+04  -9.43e+03   5.32e+04   3.62e+04   2.11e+04\n",
      "    4.05e+04   2.29e+04   5.49e+04   2.86e+04]\n",
      " [  4.18e+04   1.89e+04   1.49e+04   2.85e+04   2.58e+04   2.71e+04\n",
      "    1.11e+04   2.26e+04   4.00e+04   3.55e+04]\n",
      " [  1.90e+03   1.46e+04  -1.22e+04   7.01e+04   1.42e+04   1.51e+04\n",
      "    2.23e+04   1.86e+04   2.65e+02   2.74e+04]\n",
      " [ -1.33e+03   2.59e+04   1.38e+04  -2.12e+04   4.86e+04   3.08e+04\n",
      "    2.94e+04  -9.33e+03   3.45e+04   2.72e+04]\n",
      " [  4.10e+04   1.64e+04   9.59e+03   6.17e+04   1.29e+04   3.25e+02\n",
      "    3.57e+04   5.46e+04   1.22e+02   1.23e+04]\n",
      " [  1.07e+05   3.49e+04   2.02e+04   1.91e+03   1.23e+04  -1.78e+03\n",
      "   -3.17e+04   1.22e+03   3.20e+04   5.34e+04]\n",
      " [  3.01e+04   1.81e+04   1.21e+04   1.01e+04   4.58e+04  -4.73e+03\n",
      "    1.32e+04   2.17e+04   3.52e+04   1.81e+04]\n",
      " [  3.94e+04   1.64e+04  -5.26e+03   7.84e+04   1.44e+04  -1.86e+04\n",
      "    3.64e+04   1.05e+04   3.57e+04   5.49e+03]\n",
      " [  2.04e+04   1.36e+04   3.85e+04  -4.75e+04   1.37e+04  -1.84e+02\n",
      "   -1.36e+04   2.85e+04   2.30e+04   4.95e+04]\n",
      " [  5.36e+04   1.13e+04   4.92e+04   1.97e+04   3.56e+04  -4.77e+04\n",
      "    2.32e+04   1.05e+04   5.10e+04  -3.76e+03]\n",
      " [  3.07e+04   6.78e+04   7.73e+03  -4.10e+03   8.74e+03   8.09e+03\n",
      "    1.98e+04  -7.71e+02   5.17e+04   4.33e+04]\n",
      " [  6.30e+03   3.34e+04  -6.01e+03   1.66e+04   3.53e+04   4.15e+03\n",
      "    5.16e+04   8.54e+03   1.63e+04   1.28e+04]\n",
      " [  3.10e+03   8.54e+03   2.83e+03   9.81e+03   4.76e+04   4.16e+03\n",
      "    3.07e+04   2.40e+04   3.14e+04   2.88e+04]\n",
      " [  5.49e+04   3.19e+04  -1.83e+04   5.35e+03   2.09e+04   6.71e+04\n",
      "   -7.65e+03   3.94e+04   3.63e+04   3.94e+04]\n",
      " [  8.68e+04   4.09e+04   3.45e+04  -2.09e+04   1.60e+04  -2.03e+04\n",
      "   -1.59e+04   2.47e+04   3.62e+04   3.68e+04]\n",
      " [  3.93e+04   3.01e+02  -9.90e+03   1.35e+04  -1.18e+04   1.46e+04\n",
      "   -1.28e+03   2.49e+04   8.03e+04   2.20e+04]\n",
      " [  3.40e+04  -5.12e+03   1.92e+03   6.87e+02   7.27e+03  -1.28e+04\n",
      "    4.60e+04  -5.67e+02   3.31e+04   2.41e+04]\n",
      " [  3.12e+04   9.93e+02  -1.18e+03   1.50e+04   1.45e+04   3.42e+04\n",
      "   -5.05e+03  -2.11e+04  -1.91e+04   2.09e+04]\n",
      " [  7.28e+04   7.25e+03  -2.07e+03   2.47e+04   1.10e+04  -2.87e+04\n",
      "    2.32e+04   4.69e+04   7.30e+03   4.42e+04]\n",
      " [  6.79e+04   3.19e+04   2.96e+03   3.60e+04   1.15e+04  -2.42e+03\n",
      "    2.44e+04   3.70e+04   2.51e+04   1.95e+04]\n",
      " [  3.30e+04   3.63e+04   1.24e+04  -3.62e+04   3.62e+04   3.54e+04\n",
      "    4.11e+04   5.61e+04   1.39e+04   4.26e+04]\n",
      " [  3.31e+04   1.63e+04  -1.93e+04   6.75e+03   4.42e+04   2.69e+04\n",
      "    2.39e+04   2.83e+04   3.06e+04   2.82e+04]\n",
      " [ -5.55e+03   2.71e+03   9.70e+03   9.52e+04   9.38e+03  -1.56e+04\n",
      "    2.99e+04   1.30e+04   6.03e+03   1.81e+04]\n",
      " [  1.22e+04   4.00e+03   6.19e+03   1.16e+04   2.42e+04   3.09e+02\n",
      "    1.49e+04   2.09e+03   5.45e+04   1.34e+04]\n",
      " [  3.73e+04   4.83e+04  -1.92e+04   6.92e+04   3.32e+04   1.08e+04\n",
      "    2.58e+04   3.14e+04   4.42e+04  -1.52e+04]\n",
      " [  6.92e+04   4.48e+04   2.34e+04  -4.69e+03   4.12e+04  -3.86e+03\n",
      "    1.67e+03   7.81e+04   1.95e+04   5.92e+04]\n",
      " [ -1.40e+04   3.88e+04   1.61e+04  -1.87e+04   2.55e+04  -1.05e+04\n",
      "    3.96e+04   8.34e+04   4.95e+04   4.17e+03]\n",
      " [  2.12e+04   6.27e+03   3.94e+03   5.41e+03   7.10e+04   8.12e+03\n",
      "    1.53e+04   2.25e+04   1.77e+04   2.24e+04]\n",
      " [  4.60e+04   7.28e+04   2.17e+04  -4.19e+04   2.56e+04  -1.54e+04\n",
      "    1.49e+04   3.33e+04   5.33e+04   2.90e+04]\n",
      " [  3.65e+03   1.74e+04   3.32e+04  -1.62e+04   3.16e+04  -4.43e+03\n",
      "    3.05e+04   3.04e+04   3.34e+04   3.52e+04]\n",
      " [  1.67e+04   2.47e+04   5.55e+03  -2.68e+04   2.04e+04   8.30e+03\n",
      "    3.36e+04   2.07e+04   1.72e+04   2.41e+04]\n",
      " [  4.06e+04   2.67e+04   6.24e+03   2.50e+04   1.74e+04   8.79e+03\n",
      "    1.83e+04   3.14e+04  -2.39e+03   1.60e+04]\n",
      " [  4.63e+04   2.84e+04   1.20e+04   8.00e+03   2.11e+04   1.86e+04\n",
      "    1.47e+04   3.68e+04   7.72e+03   7.20e+04]\n",
      " [  2.81e+04   1.66e+04   4.66e+03   4.61e+04   1.04e+04   1.06e+04\n",
      "   -6.38e+03   1.19e+04   9.42e+03   2.27e+04]\n",
      " [  3.82e+04   2.58e+03   2.04e+04   3.58e+04  -2.62e+04   3.59e+04\n",
      "    2.71e+04   4.16e+04   1.45e+04  -2.45e+04]\n",
      " [  3.42e+04   1.57e+04   4.81e+04  -3.50e+04   2.79e+04   1.73e+04\n",
      "   -1.97e+04   2.79e+04   8.99e+03   4.20e+04]\n",
      " [  3.48e+04   4.57e+04   4.51e+04   4.17e+04   1.33e+04   1.04e+04\n",
      "    1.55e+04   3.79e+04   3.34e+02   3.30e+04]\n",
      " [ -1.34e+04   1.91e+04   1.57e+04  -1.45e+03   1.83e+04   7.42e+04\n",
      "    2.00e+04   6.22e+04   1.75e+04   3.09e+04]\n",
      " [  2.31e+04   1.78e+04   6.38e+03  -1.40e+04  -1.02e+04   1.26e+04\n",
      "    1.52e+04  -1.27e+04   3.99e+04   2.03e+04]\n",
      " [  4.16e+04   3.37e+04   2.86e+04  -4.45e+03  -2.23e+04   2.03e+04\n",
      "   -1.01e+04   7.12e+04   1.29e+04   3.04e+04]\n",
      " [  1.51e+04  -2.09e+04   4.92e+03  -4.87e+03   4.92e+04   5.09e+04\n",
      "    4.62e+04   6.04e+04   3.27e+04   3.32e+04]\n",
      " [ -4.69e+03   5.05e+04  -1.56e+03  -1.45e+04   1.92e+04   1.80e+04\n",
      "    3.15e+04   2.37e+04   1.68e+04   2.66e+04]\n",
      " [  2.55e+04   9.28e+03  -5.93e+04  -4.75e+02   9.64e+04   2.26e+04\n",
      "    1.54e+04   2.42e+04   1.96e+04   3.29e+04]\n",
      " [  8.43e+04   3.75e+04   1.95e+03  -6.35e+04   2.36e+04   1.06e+04\n",
      "   -3.44e+04   3.57e+04  -3.61e+03   3.58e+04]\n",
      " [  1.37e+03   2.21e+04   2.50e+04  -4.76e+03  -1.33e+04   6.44e+03\n",
      "    2.25e+04   4.50e+04   1.29e+04   2.15e+04]\n",
      " [  3.18e+04   2.52e+04   2.00e+04  -1.56e+03   1.51e+04   6.35e+04\n",
      "   -1.63e+04  -1.21e+04   3.49e+04   4.28e+04]\n",
      " [  2.04e+04   1.05e+04   2.88e+04   3.05e+04   1.16e+04  -8.76e+03\n",
      "    2.39e+04   2.11e+04   2.14e+04  -1.39e+03]\n",
      " [  1.91e+04   9.56e+03   5.70e+01   5.30e+04   1.28e+04   9.68e+03\n",
      "    1.21e+04   1.57e+04   1.77e+04  -1.00e+04]\n",
      " [  2.12e+04   7.38e+03   4.89e+03   2.14e+04   2.50e+04  -7.76e+03\n",
      "    5.68e+04   1.42e+04   9.99e+03   8.54e+03]\n",
      " [  4.77e+04   3.86e+04  -4.27e+04  -4.11e+03   2.82e+04  -9.91e+03\n",
      "    6.15e+04   5.22e+04  -3.51e+03   5.81e+04]\n",
      " [  6.04e+04   1.42e+04  -7.39e+03  -3.32e+04   6.37e+04   3.86e+04\n",
      "    6.50e+04   3.94e+04  -1.25e+03   4.07e+04]\n",
      " [  3.86e+04   3.91e+04   1.87e+04  -4.49e+04   1.29e+04  -6.05e+03\n",
      "   -2.02e+04   7.40e+04   2.94e+04   5.94e+04]\n",
      " [  4.69e+04   3.39e+04   2.33e+04   1.69e+04  -2.02e+04   1.64e+04\n",
      "    3.15e+04   2.86e+04  -2.48e+04   9.68e+04]\n",
      " [  6.12e+03   7.16e+03   1.89e+04   1.28e+03   2.41e+04   3.55e+04\n",
      "    2.83e+04   2.58e+04  -6.54e+03   1.21e+04]]\n",
      "Accuracy: 0.9\n",
      "[[0 1 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
